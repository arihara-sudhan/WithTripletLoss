{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3cc2974",
   "metadata": {},
   "source": [
    "# ‚≠ê DOCUMENT DETECTION - TRIPLET LOSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f5351",
   "metadata": {},
   "source": [
    "# ![https://w0.peakpx.com/wallpaper/209/673/HD-wallpaper-i-am-coming-running-cool-tiger.jpg](https://w0.peakpx.com/wallpaper/209/673/HD-wallpaper-i-am-coming-running-cool-tiger.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2ca688",
   "metadata": {},
   "source": [
    "# IMPORT REQUIRED LIBRARIES üåß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7279d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam,lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.nn.parallel import DataParallel\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1728d047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cafad6b",
   "metadata": {},
   "source": [
    "# MAKE INTO TRIPLETS ‚òòÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bbcc3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Triplet:\n",
    "    def __init__(self, train_folder):\n",
    "        self.train_folder = train_folder\n",
    "        self.labels = [label for label in os.listdir(train_folder) if label != '.ipynb_checkpoints']\n",
    "        self.label_to_path = {label: os.path.join(train_folder, label) for label in self.labels}\n",
    "    \n",
    "    def get_triplet(self):\n",
    "        anchor_label = random.choice(self.labels)\n",
    "        anchor_path = random.choice(os.listdir(self.label_to_path[anchor_label]))\n",
    "        positive_label = anchor_label\n",
    "        positive_path = random.choice(os.listdir(self.label_to_path[positive_label]))\n",
    "        negative_label = random.choice([label for label in self.labels if label != anchor_label])\n",
    "        negative_path = random.choice(os.listdir(self.label_to_path[negative_label]))\n",
    "        \n",
    "        anchor_image = os.path.join(self.label_to_path[anchor_label], anchor_path)\n",
    "        positive_image = os.path.join(self.label_to_path[positive_label], positive_path)\n",
    "        negative_image = os.path.join(self.label_to_path[negative_label], negative_path)\n",
    "        \n",
    "        anchor_label_num = self.labels.index(anchor_label)\n",
    "        positive_label_num = self.labels.index(positive_label)\n",
    "        negative_label_num = self.labels.index(negative_label)\n",
    "        \n",
    "        return anchor_image, positive_image, negative_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fa97e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, train_folder, length, transform=None,):\n",
    "        self.triplet_generator = Triplet(train_folder)\n",
    "        self.transform = transform\n",
    "        self.length = length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        anchor_image, positive_image, negative_image = self.triplet_generator.get_triplet()\n",
    "        anchor = self._load_image(anchor_image)\n",
    "        positive = self._load_image(positive_image)\n",
    "        negative = self._load_image(negative_image)\n",
    "        return anchor, positive, negative\n",
    "\n",
    "    def _load_image(self, image_path):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def get_triplet_names(self, index):\n",
    "        anchor_image, positive_image, negative_image = self.triplet_generator.get_triplet()\n",
    "        return anchor_image, positive_image, negative_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f3c097",
   "metadata": {},
   "source": [
    "# DATALOADER ‚è≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af38c4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f8d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "\n",
    "train_folder = \"./Datasets/RVL_CDIP/train/\"\n",
    "valid_folder = \"./Datasets/RVL_CDIP/validation/\"\n",
    "test_folder = \"./Datasets/RVL_CDIP/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c6ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acae4d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TripletDataset(train_folder, 320000, transform=transform, )\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c22cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = TripletDataset(valid_folder, 40000, transform=transform, )\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c87e3643",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TripletDataset(test_folder, 33669, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0733eab2",
   "metadata": {},
   "source": [
    "# THE MODEL ‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a748a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        resnet50 = models.resnet50(pretrained=True)\n",
    "        self.convnet = nn.Sequential(*list(resnet50.children())[:-1])  # Remove the fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.convnet(x)\n",
    "        return output\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dc52a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = EmbeddingNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8081405",
   "metadata": {},
   "source": [
    "# TRIPLET WRAPPER ‚òòÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89129096",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embedding_net = embedding_net\n",
    "\n",
    "    def forward(self, x1, x2=None, x3=None):\n",
    "        if x2 is None and x3 is None:\n",
    "            return self.embedding_net(x1)\n",
    "        return self.embedding_net(x1),self.embedding_net(x2),self.embedding_net(x3)\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.embedding_net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e68c0",
   "metadata": {},
   "source": [
    "# TRIPLET LOSS üìà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "644c813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative, size_average=True):\n",
    "        distance_positive = torch.norm(anchor - positive, dim=1)\n",
    "        distance_negative = torch.norm(anchor - negative, dim=1)\n",
    "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean() if size_average else losses.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a4e96",
   "metadata": {},
   "source": [
    "# SET THE STUFFS UP  üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4433101",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TripletNet(emb)\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "margin = 1\n",
    "lr = 0.0001\n",
    "n_epochs = 10\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "loss_fn = TripletLoss(margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56fc68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd2454f0",
   "metadata": {},
   "source": [
    "# EVALUATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4891d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, triplet_test_loader,for_log=False,LIMIT=None):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for idx,(anchor, positive, negative) in enumerate(triplet_test_loader):\n",
    "            if for_log and idx==LIMIT:\n",
    "                return f'ACCURACY: {correct/total*100}% ,TIME: {time.time()-start}'\n",
    "            anchor_embedding, positive_embedding, negative_embedding = model(anchor.to(device),\n",
    "                                                                             positive.to(device),\n",
    "                                                                             negative.to(device))\n",
    "            distance_positive = torch.norm(anchor_embedding - positive_embedding, dim=1).to(device)\n",
    "            distance_negative = torch.norm(anchor_embedding - negative_embedding, dim=1).to(device)\n",
    "            correct += torch.sum(distance_positive < distance_negative).item()\n",
    "            total += anchor.size(0)\n",
    "    accuracy = correct / total\n",
    "    print(accuracy*100,time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b16ace4",
   "metadata": {},
   "source": [
    "# TRAIN ü¶ú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c75d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, num_epochs, train_loader,bs):\n",
    "    for epoch in range(n_epochs):\n",
    "        start = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for idx, batch in enumerate(train_loader):\n",
    "            anchor, positive, negative = batch\n",
    "            anchor = anchor.to(device)\n",
    "            positive = positive.to(device)\n",
    "            negative = negative.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            anchor_embedding, positive_embedding, negative_embedding = model(anchor, positive, negative)\n",
    "            anchor_embedding.requires_grad_(True)\n",
    "            positive_embedding.requires_grad_(True)\n",
    "            negative_embedding.requires_grad_(True)\n",
    "            loss = loss_fn(anchor_embedding, positive_embedding, negative_embedding)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            print(f\"({idx + 1}).  LOSS : {loss.item()}  SEEN : {bs * (idx + 1)}/{len(train_loader.dataset)}\")\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Train Loss: {train_loss / len(train_loader):.4f}, TIME: {time.time()-start}\")\n",
    "        print('VALIDATION :')\n",
    "        evaluate_model(model, valid_loader)\n",
    "        print('TESTING :')\n",
    "        evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17dc411d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit(model,n_epochs,train_loader,bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf830a1",
   "metadata": {},
   "source": [
    "# EVALUATE THE MODEL ‚öñÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7dd9ff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_model(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01780301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_model(model,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "549e664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './Models/rvl50.pth'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aff02ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL SAVED!\n"
     ]
    }
   ],
   "source": [
    "print(\"MODEL SAVED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53d329e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(model_path)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b3d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc5e6ee",
   "metadata": {},
   "source": [
    "# WITH FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "110e0ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1208c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        self._load_images()\n",
    "\n",
    "    def _load_images(self):\n",
    "        valid_extensions = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
    "        for class_name in os.listdir(self.folder_path):\n",
    "            class_folder = os.path.join(self.folder_path, class_name)\n",
    "            if os.path.isdir(class_folder):\n",
    "                for filename in os.listdir(class_folder):\n",
    "                    if filename.lower().endswith(valid_extensions):\n",
    "                        self.image_paths.append(os.path.join(class_folder, filename))\n",
    "                        self.labels.append(class_name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b616b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d49f08b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"./Datasets/RVL_CDIP_MINI/train/\"\n",
    "valid_folder = \"./Datasets/RVL_CDIP_MINI/validation/\"\n",
    "test_folder = \"./Datasets/RVL_CDIP_MINI/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71c3a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(CustomDataset(test_folder,transform=transform))\n",
    "train_dataloader = DataLoader(CustomDataset(train_folder,transform=transform))\n",
    "valid_dataloader = DataLoader(CustomDataset(valid_folder,transform=transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d283783b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe70707",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embs = None\n",
    "train_labels = []\n",
    "for idx,i in enumerate(train_dataloader):\n",
    "    I, L = i\n",
    "    train_labels.append(L)\n",
    "    emb = model(I) # Assuming `model_loaded(I)` returns a PyTorch tensor\n",
    "    emb = emb.detach()\n",
    "    if train_embs is None:\n",
    "        train_embs = emb\n",
    "    else:\n",
    "        train_embs = torch.cat((train_embs, emb), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd5a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embs = None\n",
    "test_labels = []\n",
    "for idx,i in enumerate(test_dataloader):\n",
    "    I, L = i\n",
    "    test_labels.append(L)\n",
    "    emb = model(I) # Assuming `model_loaded(I)` returns a PyTorch tensor\n",
    "    emb = emb.detach()\n",
    "    if test_embs is None:\n",
    "        test_embs = emb\n",
    "    else:\n",
    "        test_embs = torch.cat((test_embs, emb), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da45f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_embs = None\n",
    "valid_labels = []\n",
    "for idx,i in enumerate(valid_dataloader):\n",
    "    I, L = i\n",
    "    valid_labels.append(L)\n",
    "    emb = model(I) # Assuming `model_loaded(I)` returns a PyTorch tensor\n",
    "    emb = emb.detach()\n",
    "    if valid_embs is None:\n",
    "        valid_embs = emb\n",
    "    else:\n",
    "        valid_embs = torch.cat((valid_embs, emb), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28815fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Pickles/teste.pkl', 'wb') as f:\n",
    "    pickle.dump(test_embs, f)\n",
    "\n",
    "with open('./Pickles/testl.pkl', 'wb') as f:\n",
    "    pickle.dump(test_labels, f)\n",
    "\n",
    "with open('./Pickles/valide.pkl', 'wb') as f:\n",
    "    pickle.dump(valid_embs, f)\n",
    "\n",
    "with open('./Pickles/validl.pkl', 'wb') as f:\n",
    "    pickle.dump(valid_labels, f)\n",
    "\n",
    "with open('./Pickles/traine.pkl', 'wb') as f:\n",
    "    pickle.dump(train_embs, f)\n",
    "\n",
    "with open('./Pickles/trainl.pkl', 'wb') as f:\n",
    "    pickle.dump(train_labels, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78894cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Pickles/traine.pkl', 'rb') as f:\n",
    "    train_embs = pickle.load(f)\n",
    "\n",
    "with open('./Pickles/teste.pkl', 'rb') as f:\n",
    "    test_embs = pickle.load(f)\n",
    "\n",
    "\n",
    "with open('./Pickles/trainl.pkl', 'rb') as f:\n",
    "    train_labels = pickle.load(f)\n",
    "\n",
    "with open('./Pickles/testl.pkl', 'rb') as f:\n",
    "    test_labels = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d564734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def kmeans_clustering(train_embs, test_embs, labels1, labels2, num_clusters):\n",
    "    # Reshape train_embs and test_embs to have shape (num_samples, embedding_dim)\n",
    "    train_embs = train_embs.reshape(train_embs.shape[0], -1)\n",
    "    test_embs = test_embs.reshape(test_embs.shape[0], -1)\n",
    "    all_embs = np.vstack((train_embs, test_embs))\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(all_embs)\n",
    "    train_cluster_labels = cluster_labels[:len(train_embs)]\n",
    "    test_cluster_labels = cluster_labels[len(train_embs):]\n",
    "    labels1 = np.array(labels1, dtype=np.int)\n",
    "    labels1 = labels1.flatten()\n",
    "    cluster_to_label = {}\n",
    "    for cluster_id in range(num_clusters):\n",
    "        cluster_samples = labels1[train_cluster_labels == cluster_id]\n",
    "        label_counts = np.bincount(cluster_samples)\n",
    "        cluster_to_label[cluster_id] = np.argmax(label_counts)\n",
    "    predicted_labels = np.array([cluster_to_label[cluster_id] for cluster_id in test_cluster_labels])\n",
    "    labels2 = np.array(labels2, dtype=np.int)\n",
    "    acc = accuracy_score(labels2, predicted_labels)\n",
    "    return acc\n",
    "\n",
    "num_clusters = 16\n",
    "\n",
    "accuracy = kmeans_clustering(train_embs.cpu(), test_embs.cpu(), train_labels, test_labels, num_clusters)\n",
    "print(f\"Accuracy using K-Means Clustering: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6672d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "151c43ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embs_cpu_np = train_embs.cpu().numpy()\n",
    "embs_cpu_np = embs_cpu_np.reshape(embs_cpu_np.shape[0], -1)\n",
    "\n",
    "index1 = faiss.IndexFlatL2(embs_cpu_np.shape[1])  # Assuming embs_cpu_np.shape[1] represents the dimensionality of the embeddings\n",
    "index1.add(embs_cpu_np)\n",
    "\n",
    "nlist = 100  # Number of cells/buckets\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(embs_cpu_np.shape[1])  # Quantizer index (same as IndexFlatL2)\n",
    "index2 = faiss.IndexIVFFlat(quantizer, embs_cpu_np.shape[1], nlist)\n",
    "index2.train(embs_cpu_np)\n",
    "index2.add(embs_cpu_np)\n",
    "\n",
    "index3 = faiss.IndexHNSWFlat(embs_cpu_np.shape[1], 128)  # M = 32 for the HNSW index\n",
    "index3.add(embs_cpu_np)\n",
    "\n",
    "nbits = 8  # Number of bits for the LSH hash\n",
    "index4 = faiss.IndexLSH(embs_cpu_np.shape[1], nbits)\n",
    "index4.add(embs_cpu_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8aa18dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatewithfaiss(embs,index):\n",
    "    TOTAL = len(embs)\n",
    "    CORRECT = 0\n",
    "    start = time.time()\n",
    "    for idx,emb in enumerate(embs):\n",
    "        label = index.search(emb.reshape(1,-1),1)[1][0][0]\n",
    "        if train_labels[label][0]==test_labels[idx][0]:\n",
    "            CORRECT += 1\n",
    "    return f'{CORRECT}/{TOTAL}={(CORRECT/TOTAL)*100}',f'TIME = {time.time()-start} SECONDS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49de7f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs2_cpu_np = test_embs.cpu().numpy()\n",
    "embs2_cpu_np = embs2_cpu_np.reshape(embs2_cpu_np.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850663c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexIVFFlat : ('27638/33669=82.08738008256854', 'TIME = 207.90258765220642 SECONDS')\n",
      "IndexHNSWFlat : ('28038/33669=83.27541655528825', 'TIME = 60.388715505599976 SECONDS')\n",
      "IndexLSH : ('2243/33669=6.661914520775788', 'TIME = 29.91447877883911 SECONDS')\n"
     ]
    }
   ],
   "source": [
    "print(f'IndexIVFFlat : {evaluatewithfaiss(embs2_cpu_np,index2)}')\n",
    "print(f'IndexHNSWFlat : {evaluatewithfaiss(embs2_cpu_np,index3)}')\n",
    "print(f'IndexLSH : {evaluatewithfaiss(embs2_cpu_np,index4)}')\n",
    "#print(f'IndexFlatL2 : {evaluatewithfaiss(embs2_cpu_np,index1)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
